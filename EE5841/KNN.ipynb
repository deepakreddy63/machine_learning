{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KNN on MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Deepak Reddy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing MNIST package to read the downloaded MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "images_train, labels_train = mndata.load_training()\n",
    "images_test, labels_test = mndata.load_testing()\n",
    "\n",
    "images_train  = np.asarray(images_train)\n",
    "images_test  = np.asarray(images_test)\n",
    "labels_train = np.asarray(labels_train)\n",
    "labels_test = np.asarray(labels_test)\n",
    "print(len(images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "...................@........\n",
      "...................@........\n",
      "..................@@........\n",
      ".................@@.........\n",
      "................@@..........\n",
      "................@@..........\n",
      "...............@@...........\n",
      "..............@@............\n",
      ".............@@.............\n",
      "............@@..............\n",
      "...........@@...............\n",
      "...........@....@@@@........\n",
      "..........@@..@@@@@@........\n",
      ".........@@..@.....@........\n",
      ".........@@........@........\n",
      "........@@..@...............\n",
      "........@@@@.....@..........\n",
      "........@@@@..@@@...........\n",
      ".........@@@@@@.............\n",
      "..........@@@@@.............\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n"
     ]
    }
   ],
   "source": [
    "index = random.randrange(0, len(images_train))  # choose an index ;-)\n",
    "print(mndata.display(images_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1-Nearest neighbor on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030.1677399137916\n"
     ]
    }
   ],
   "source": [
    "predict = np.zeros(len(images_test)) \n",
    "\n",
    "start = time.clock()\n",
    "for i in range(len(images_test)):\n",
    "    diff = images_train - images_test[i]\n",
    "    dist = np.einsum('ij, ij->i', diff, diff)\n",
    "    predict[i] = labels_train[np.argsort(dist)[0]]\n",
    "\n",
    "end = time.clock()\n",
    "print((end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating error for the 1-NN and ouputting the error for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error: 309\n",
      "Error for the digits : (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([ 7,  6, 40, 40, 38, 32, 14, 36, 54, 42], dtype=int64))\n",
      "Predicted  0.0   1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
      "Actual                                                      \n",
      "0          973     1    1    0    0    1    3    1    0    0\n",
      "1            0  1129    3    0    1    1    1    0    0    0\n",
      "2            7     6  992    5    1    0    2   16    3    0\n",
      "3            0     1    2  970    1   19    0    7    7    3\n",
      "4            0     7    0    0  944    0    3    5    1   22\n",
      "5            1     1    0   12    2  860    5    1    6    4\n",
      "6            4     2    0    0    3    5  944    0    0    0\n",
      "7            0    14    6    2    4    0    0  992    0   10\n",
      "8            6     1    3   14    5   13    3    4  920    5\n",
      "9            2     5    1    6   10    5    1   11    1  967\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(len(images_test)):\n",
    "    if predict[i] != labels_test[i]:\n",
    "        error = error+1\n",
    "print(\"Total Error:\", error)\n",
    "print(\"Error for the digits :\", np.unique(pts, return_counts=True))\n",
    "\n",
    "#Output confusion matrix \n",
    "y_actu = pd.Series(labels_test, name='Actual')\n",
    "y_pred = pd.Series(predict, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data in output_1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output_1.txt', 'wb') as fp:\n",
    "    pickle.dump(predict, fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('output_1.txt', 'rb') as fp:\n",
    "    predict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "it took 1030 secs to classify all the test set(10000 images) using train set. Then error was calculated which is total mispredicted values(309) for one nearest neighbor. Finally, confusion matrix is generated which represents the correct classification and testing error for test set. We got error of 309 which gives an accuracy of 96.91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Function for leave one out approach applied on images_train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leave_one_out(train_set,train_labels):\n",
    "    predict = []\n",
    "   \n",
    "    for i in range(len(train_set)):\n",
    "        diff = train_set - train_set[i]\n",
    "        dist = np.einsum('ij, ij->i', diff, diff)\n",
    "\n",
    "        predict.append(train_labels[np.argsort(dist)[1:21]])\n",
    "        #    print(mode(nearest)[0][0])\n",
    "\n",
    "    return(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing the leave_one_out function on the whole images_train set(60000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307.605931746744\n",
      "(60000, 20)\n"
     ]
    }
   ],
   "source": [
    "train_set = images_train\n",
    "train_labels = labels_train\n",
    "start = time.clock()\n",
    "predict_k = leave_one_out(train_set,train_labels)\n",
    "end = time.clock()\n",
    "print(end-start)\n",
    "predict_k = np.asarray(predict_k)\n",
    "#print(predict_k[:10])\n",
    "print(predict_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "It took 6307 secs to perform leave on out method on train set. Output is 60000by20 matrix where each row is the 20 vector train labels which are closest to that digit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the predict_k variable in output_2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('output_2.txt', 'wb') as fp:\n",
    "    pickle.dump(predict_k, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 20)\n"
     ]
    }
   ],
   "source": [
    "with open ('output_2.txt', 'rb') as fp:\n",
    "    predict_k = np.asarray(pickle.load(fp))\n",
    "print(predict_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for KNN_classifier to operate on 'predict_k' data and outputs error and predict vector for that k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN_classifier(pred, k, labels):\n",
    "    error = 0\n",
    "    pred_label = np.empty(len(pred))\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][:k]\n",
    "        pred_sort = np.unique(predict, return_counts=True)\n",
    "        pred_label[i] = pred_sort[0][np.argmax(pred_sort[1])]\n",
    "        if labels[i] != pred_label[i]:\n",
    "            error = error+1\n",
    "    return error, pred_label\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculating the error and plotting the error Vs K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1577.  1926.  1562.  1643.  1635.  1694.  1698.  1751.  1787.  1847.\n",
      "  1898.  1942.  1946.  2008.  2020.  2046.  2084.  2109.  2158.  2173.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKLy/93pqueNTS1kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2828e2ee860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = np.zeros(20)\n",
    "for k in range(1,21):\n",
    "    error[k-1],p = KNN_classifier(predict_k,k,train_labels)\n",
    "    \n",
    "print(error)\n",
    "\n",
    "plt.plot(np.arange(1,21), error)\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('k')\n",
    "plt.title('error Vs K')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the images_test 20 NN file output('output_1_k20.txt') generated earlier to find the testing error for best value k = 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n",
      "Total error = 295\n",
      "Predicted  0.0   1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
      "Actual                                                      \n",
      "0          974     1    1    0    0    1    2    1    0    0\n",
      "1            0  1133    2    0    0    0    0    0    0    0\n",
      "2           10     9  996    2    0    0    0   13    2    0\n",
      "3            0     2    4  976    1   13    1    7    3    3\n",
      "4            1     6    0    0  950    0    4    2    0   19\n",
      "5            6     1    0   11    2  859    5    1    3    4\n",
      "6            5     3    0    0    3    3  944    0    0    0\n",
      "7            0    21    5    0    1    0    0  991    0   10\n",
      "8            8     2    4   16    8   11    3    4  914    4\n",
      "9            4     5    2    8    9    2    1    8    2  968\n"
     ]
    }
   ],
   "source": [
    "with open ('output_1_k20.txt', 'rb') as fp:\n",
    "    predict_3 = np.asarray(pickle.load(fp))\n",
    "print(predict_3.shape)\n",
    "error3, predict_3 = KNN_classifier(predict_3, 3, labels_test)\n",
    "#Output confusion matrix \n",
    "y_actu = pd.Series(labels_test, name='Actual')\n",
    "y_pred = pd.Series(predict_3, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(\"Total error =\", error3)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "After we get the predict matrix, we use KNN classifier function to get the errors for each K = 1 to 20. Then we select the K index with least error value to get the best value of K equal to 3. This K is applied in KNN classifier applied for predict set test matrix which was generated and stored in 'output_1_k20.txt' in the first part. We get error of 295 for K = 3 on test set which gives accuracy of 97.05%.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Function for downsampling the image by factor n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsample(img,n):\n",
    "    no_samples = len(img)//n\n",
    "    indices = n* (np.arange(no_samples))\n",
    "    downsamp_img = img[indices]\n",
    "    return downsamp_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure to downsample for 4 n values of [2,4,8,16] and calculating error for each n value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 392)\n",
      "5780.444989736352\n",
      "[ 1790.  2191.  1798.  1866.  1811.  1888.  1912.  1959.  2015.  2051.\n",
      "  2066.  2136.  2156.  2216.  2239.  2297.  2333.  2349.  2377.  2407.]\n",
      "(60000, 196)\n",
      "3034.197574892547\n",
      "[ 4209.  4863.  4037.  4156.  4012.  4113.  4136.  4225.  4254.  4338.\n",
      "  4356.  4448.  4456.  4557.  4591.  4629.  4698.  4728.  4747.  4811.]\n",
      "(60000, 98)\n",
      "1678.574066008092\n",
      "[ 5110.  5641.  4705.  4687.  4592.  4664.  4637.  4691.  4723.  4762.\n",
      "  4793.  4865.  4879.  4920.  4970.  5013.  5081.  5129.  5164.  5185.]\n",
      "(60000, 49)\n",
      "994.7438328308344\n",
      "[ 12961.  13330.  11931.  11693.  11441.  11318.  11225.  11169.  11140.\n",
      "  11233.  11162.  11153.  11162.  11248.  11259.  11284.  11337.  11278.\n",
      "  11333.  11378.]\n",
      "(4, 60000, 20)\n"
     ]
    }
   ],
   "source": [
    "final_predict = []\n",
    "for n in [2, 4, 8, 16]:\n",
    "    d_img = np.empty([images_train.shape[0],images_train.shape[1]//n])\n",
    "    for i in range(images_train.shape[0]):\n",
    "        d_img[i] =  downsample(images_train[i],n)\n",
    "    print(d_img.shape)\n",
    "    train_set = d_img\n",
    "    train_labels = labels_train\n",
    "    \n",
    "    start = time.clock()\n",
    "    predict_k_4 = leave_one_out(train_set,train_labels)\n",
    "    end = time.clock()\n",
    "    print(end-start)\n",
    "    \n",
    "    predict_k_4 = np.asarray(predict_k_4)\n",
    "    #print(predict_k_4[:10])\n",
    "    final_predict.append(predict_k_4)\n",
    "    \n",
    "    error = np.zeros(20)\n",
    "    for k in range(1,21):\n",
    "        error[k-1], p = KNN_classifier(predict_k_4,k,train_labels)\n",
    "    print(error)\n",
    "print(np.asarray(final_predict).shape)\n",
    "    \n",
    "import pickle\n",
    "with open('output_3.txt', 'wb') as fp:\n",
    "    pickle.dump(final_predict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "Above we output the downsampled train_images matrix shape, querytime and error values for K = 1 to 20 for n = 2, 4, 8 and 16 respectively. Best value of K for n = [2,4,8,16] is [1, 5, 5, 9] respectively.\n",
    "Accuracy values for n = 2 is 97.04%, n= 4 is 93.31%, n= 8 is 92.34% and n =16 is 81.43%.\n",
    "We observe that for n = 2, the time is 5780 sec and for n = 4 it is 3034 sec which is almost half and this trend continues for n = 8 and 16. \n",
    "Also the error for n = 2 is comparable to original image size and proves that just downsampling by 2 doesn't affect much regarding the error but downsampling by 4, 8 and 16 worsens the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open ('output_k.txt', 'rb') as fp:\n",
    "#    itemlist = pickle.load(fp)\n",
    "#print(np.asarray(itemlist).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Function for smartdownsampling the image by factor n*n  by binning n*n samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smartdownsample(img,n):\n",
    "    img_2D = img.reshape(28,28)\n",
    "    no_samples = len(img_2D)//n\n",
    "    img_binned = np.zeros([no_samples,no_samples])\n",
    "    for i in range(no_samples):\n",
    "        for j in range(no_samples):\n",
    "            img_binned[i,j] = img_2D[i*n:(i+1)*n, j*n:(j+1)*n].sum()\n",
    "    return img_binned            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 49)\n"
     ]
    }
   ],
   "source": [
    "img_1D = np.empty([images_train.shape[0],images_train.shape[1]//16])\n",
    "for i in range(images_train.shape[0]):\n",
    "    img_1 =  smartdownsample(images_train[4],4)\n",
    "    img_1D[i] = img_1.flatten()\n",
    "print(img_1D.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure to smartdownsample for 4 n values of [2,4,7,14] and calculating error for each n value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 196)\n",
      "3032.2206751555495\n",
      "[ 1376.  1624.  1312.  1367.  1379.  1436.  1442.  1503.  1526.  1583.\n",
      "  1623.  1655.  1696.  1718.  1740.  1787.  1824.  1819.  1872.  1899.]\n",
      "(60000, 49)\n",
      "992.1595230611565\n",
      "[ 2724.  2967.  2586.  2547.  2633.  2602.  2667.  2694.  2715.  2733.\n",
      "  2798.  2822.  2886.  2908.  2960.  2968.  3018.  3032.  3088.  3103.]\n",
      "(60000, 16)\n",
      "472.90317467445857\n",
      "[ 11806.  12326.  10730.  10397.  10125.  10075.   9938.   9972.   9941.\n",
      "   9955.   9929.   9935.   9924.   9930.   9947.  10017.  10085.  10110.\n",
      "  10168.  10207.]\n",
      "(60000, 4)\n",
      "295.6983052152209\n",
      "[ 35404.  34818.  33517.  32454.  31974.  31447.  31037.  30872.  30573.\n",
      "  30407.  30271.  30143.  30040.  29957.  29822.  29741.  29636.  29549.\n",
      "  29470.  29426.]\n",
      "(4, 60000, 20)\n"
     ]
    }
   ],
   "source": [
    "final_predict_2D = []\n",
    "for n in [2, 4, 7, 14]:\n",
    "    img_1D = np.empty([images_train.shape[0],images_train.shape[1]//(n*n)])\n",
    "    for i in range(images_train.shape[0]):\n",
    "        img_1 =  smartdownsample(images_train[i],n)\n",
    "        img_1D[i] = img_1.flatten()\n",
    "    print(img_1D.shape)\n",
    "    train_set = img_1D\n",
    "    train_labels = labels_train\n",
    "    start = time.clock()\n",
    "    predict_k_4_2D = leave_one_out(train_set,train_labels)\n",
    "    end = time.clock()\n",
    "    print(end-start)\n",
    "    predict_k_4_2D = np.asarray(predict_k_4_2D)\n",
    "    #print(predict_k_4[:10])\n",
    "    final_predict_2D.append(predict_k_4_2D)\n",
    "    error = np.zeros(20)\n",
    "    for k in range(1,21):\n",
    "        error[k-1], p = KNN_classifier(predict_k_4_2D,k,train_labels)\n",
    "    \n",
    "    print(error)\n",
    "print(np.asarray(final_predict_2D).shape)\n",
    "import pickle\n",
    "with open('output_4.txt', 'wb') as fp:\n",
    "    pickle.dump(final_predict_2D, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "Above we output the smartdownsampled train_images matrix shape, querytime and error values for K = 1 to 20 for n = 2, 4, 7, 14 respectively. Best value of K for n = [2,4,7,14] is [3, 4, 13, 20] respectively.\n",
    "Accuracy values for n = 2 is 97.81%, n = 4 is 95.75%, n = 7 is 83.46% and n = 14 is 50.95%.\n",
    "We observe that for n = 2, the time is 3032 sec same as n = 4 for just downsampled train data and for n = 4 it is 992 sec which is almost one-third. \n",
    "Also the error for n = 2 is comparable to original image size error and proves that smartdownsampling by 2 is effective in reducing computing time by 1/2 with almost same error. Smartdownsampling by 4, 8 and 16 worsens the prediction. Still n = 4 gives good trade off for error Vs computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open ('output_2.txt', 'rb') as fp:\n",
    "#    itemlist = pickle.load(fp)\n",
    "#print(np.asarray(itemlist).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Applying smartdownsampling for n = 28  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of smartdownsampled image: (60000, 1)\n",
      "Query time: 236.2747735019293\n",
      "Error value for K = 1 to 20: [ 36324.  38708.  39714.  40324.  40800.  41342.  41878.  42290.  42550.\n",
      "  42861.  42968.  43242.  43394.  43573.  43632.  43848.  43974.  44068.\n",
      "  44114.  44189.]\n",
      "Shape of predict matrix for K =20: (60000, 20)\n",
      "Best value of k: 1\n"
     ]
    }
   ],
   "source": [
    "n = 28\n",
    "img_1D = np.empty([images_train.shape[0],images_train.shape[1]//(n*n)])\n",
    "for i in range(images_train.shape[0]):\n",
    "    img_1 =  smartdownsample(images_train[i],n)\n",
    "    img_1D[i] = img_1.flatten()\n",
    "print(\"Shape of smartdownsampled image:\", img_1D.shape)\n",
    "train_set = img_1D\n",
    "train_labels = labels_train\n",
    "start = time.clock()\n",
    "predict_k_28_2D = leave_one_out(train_set,train_labels)\n",
    "end = time.clock()\n",
    "print(\"Query time:\",end-start)\n",
    "predict_k_28_2D = np.asarray(predict_k_28_2D)\n",
    "\n",
    "error = np.zeros(20)\n",
    "for k in range(1,21):\n",
    "    error[k-1], p = KNN_classifier(predict_k_28_2D,k,train_labels)\n",
    "    \n",
    "print(\"Error value for K = 1 to 20:\",error)\n",
    "print(\"Shape of predict matrix for K =20:\", predict_k_28_2D.shape)\n",
    "print(\"Best value of k:\", np.argmin(error)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using best value of k = 1 from above leave one out approach and applying it to test_images to get the error and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix: (10000, 1)\n",
      "Query time:  5.367129097885481\n",
      "Total Error: 7201\n",
      "Predicted matrix shape for k=20: (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "n = 28\n",
    "img_1D_test = np.empty([images_test.shape[0],images_test.shape[1]//(n*n)])\n",
    "for i in range(images_test.shape[0]):\n",
    "    img_1 =  smartdownsample(images_test[i],n)\n",
    "    img_1D_test[i] = img_1.flatten()\n",
    "print(\"Feature matrix:\", img_1D_test.shape)\n",
    "test_set = img_1D_test\n",
    "test_labels = labels_test\n",
    "start = time.clock()\n",
    "predict_k_28_2Dtest = leave_one_out(test_set,test_labels)\n",
    "end = time.clock()\n",
    "print(\"Query time: \", end-start)\n",
    "predict_k_28_2Dtest = np.asarray(predict_k_28_2Dtest)\n",
    "\n",
    "errortest, p = KNN_classifier(predict_k_28_2Dtest,1,test_labels)\n",
    "print(\"Total Error:\", errortest)\n",
    "print(\"Predicted matrix shape for k=20:\", predict_k_28_2Dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
      "Actual                                                     \n",
      "0          257   14  140  107   67   67  102   51  120   55\n",
      "1           14  662   37   36   93   60   41  110   15   67\n",
      "2          120   40  262   90   83   71   88   82  111   85\n",
      "3          116   44   90  239   67   83   94   87   93   97\n",
      "4           57   88   75   73  249   83   89   97   86   85\n",
      "5           54   58   72   93   86  211   65   81   82   90\n",
      "6          104   43   95   91   89   78  198   63   97  100\n",
      "7           57  106   75   87  104   88   71  276   59  105\n",
      "8          134   26  114   97   69  103   83   55  209   84\n",
      "9           65   62   76   81  100   86  101  115   87  236\n"
     ]
    }
   ],
   "source": [
    "#Output confusion matrix \n",
    "y_actu = pd.Series(test_labels, name='Actual')\n",
    "y_pred = pd.Series(p, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "For n = 28 smart downsampling we have only one feature for image and the error is almost for half of predictions. We can see confusion matrix above for k = 1 which gives error for each digit. From confusion matrix it is seen that digit 1 is givivng best predicton. Accuracy on test set is 27.99%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Using PCA for feature transformation and applying it for predicting test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure:\n",
    "I used Principal Component Analysis method for feature transformation. I used the svd_pca function to implement using singular value decomposition. Input to function is whole set of images_train and images_test vertically stacked in to one matrix of shape  of 70000by784. \n",
    "After passing this matrix as data with k value of 40 as input to svd_pca function, i got output of 70000by40 feature transformed matrix. In effect, we are transforming the 784 vector in to 40 dimension vector. I applied leave one out on the train pca set of 60000 samples. Then i compared the last 10000 samples which are the test_images samples with the first 60000 samples to predict the test digits using the train set. We then proceed with KNN method already used above where we get the best value of KNN and use it on test set.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svd_pca(data, k):\n",
    "    \"\"\"Reduce DATA using its K principal components.\"\"\"\n",
    "    data = data.astype(\"float64\")\n",
    "    data -= np.mean(data, axis=0)\n",
    "    U, S, V = np.linalg.svd(data, full_matrices=False)\n",
    "    return U[:,:k].dot(np.diag(S)[:k,:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying leave one out on train set and classifying test set using train set to get the predict matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data input shape of train and test original images: (70000, 784)\n",
      "Data input shape of train and test pca images: (70000, 40)\n",
      "Query time: 1003.2450085749624\n",
      "predict_train shape for KNN =20: (60000, 20)\n",
      "predict_test shape for KNN =20: (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "img_pca_1 = np.vstack([images_train[:len(images_train)],images_test[:10000]])\n",
    "print(\"Data input shape of train and test original images:\", img_pca_1.shape)\n",
    "\n",
    "img_pca_1 = svd_pca(img_pca_1,40)\n",
    "print(\"Data input shape of train and test pca images:\", img_pca_1.shape)\n",
    "\n",
    "predict_pca_train = [] \n",
    "predict_pca_test =[]\n",
    "start = time.clock()\n",
    "\n",
    "#Applying leave one out on train set(first 60000 samples)\n",
    "train_set = img_pca_1[:len(images_train)]\n",
    "train_labels = labels_train\n",
    "predict_pca_train = leave_one_out(train_set,train_labels)\n",
    "\n",
    "#Test set classification using train set(last 10000 samples)\n",
    "for i in range(len(images_train), len(img_pca_1)):\n",
    "    diff = img_pca_1[:len(images_train)] - img_pca_1[i]\n",
    "    dist = np.einsum('ij, ij->i', diff, diff)\n",
    "    predict_pca_test.append(labels_train[np.argsort(dist)[:20]])\n",
    "\n",
    "end = time.clock()\n",
    "print(\"Query time:\", (end-start))\n",
    "predict_pca_train = np.asarray(predict_pca_train)\n",
    "predict_pca_test = np.asarray(predict_pca_test)\n",
    "print(\"predict_train shape for KNN =20:\", predict_pca_train.shape)\n",
    "print(\"predict_test shape for KNN =20:\", predict_pca_test.shape)\n",
    "\n",
    "with open('output_5.txt', 'wb') as fp:\n",
    "    pickle.dump(predict_pca, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain best KNN value from predict_pca variable and generating confusion matrix for best value of KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for KNN = 1 to 20: [ 1344.  1540.  1284.  1333.  1315.  1364.  1347.  1382.  1419.  1432.\n",
      "  1474.  1521.  1557.  1582.  1613.  1658.  1679.  1691.  1735.  1753.]\n",
      "Best value of k: 3 Error: 1284.0\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,21):\n",
    "    error[k-1], p = KNN_classifier(predict_pca_train,k,train_labels)\n",
    "    \n",
    "print(\"Error for KNN = 1 to 20:\", error)\n",
    "print(\"Best value of k:\", np.argmin(error)+1, \"Error:\", error[np.argmin(error)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 256\n",
      "Predicted  0.0   1.0   2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
      "Actual                                                       \n",
      "0          975     1     1    0    0    1    1    1    0    0\n",
      "1            0  1131     3    0    0    0    0    0    0    1\n",
      "2            5     1  1010    1    0    0    2   11    2    0\n",
      "3            0     1     4  973    1   13    0    6   10    2\n",
      "4            2     0     0    0  954    0    4    1    1   20\n",
      "5            5     2     0   11    2  862    4    1    2    3\n",
      "6            4     4     0    0    3    1  945    0    1    0\n",
      "7            0    15     9    1    2    0    0  992    0    9\n",
      "8            4     0     4   16    2    7    3    3  931    4\n",
      "9            6     4     3    7    8    2    1    2    5  971\n"
     ]
    }
   ],
   "source": [
    "#Output confusion matrix for K = 3\n",
    "errortest, p = KNN_classifier(predict_pca_test,3,labels_test)\n",
    "y_actu = pd.Series(labels_test, name='Actual')\n",
    "y_pred = pd.Series(p, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "print(\"Error:\", errortest)\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "PCA gives the output in k coloumn vectors which can be defined in svd_pca function. In my case, i took k = 40 which transforms 70000by784 matrix to 70000by40 matrix which consists of 40 most important pca vectors of the images.  \n",
    "\n",
    "Applied KNN method for K = 1 to 20 values and error was output for each K value. Then least error value is chosen to be best value of K which is then used to generate confusion matrix.\n",
    "\n",
    "The prediction accuracy is better after pca transformation which can be seen from change of error value of 295 for K =3 for original test set and error value of 256 for K = 3 for PCA transformed test set.\n",
    "\n",
    "Query time also reduced by approximately 7 times after pca transformation when compared with original images. For instance, it took 6307 secs for leave one out and 1030 secs for images_test prediction using train set which gives a total of 7337 secs execution time. In contrast, it took total of 1003 secs combined for both leave one out and test set prediction for PCA method.\n",
    "\n",
    "Accuracy after PCA transformation on test set is 97.44%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "https://steven.codes/blog/ml/how-to-get-97-percent-on-MNIST-with-KNN/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
